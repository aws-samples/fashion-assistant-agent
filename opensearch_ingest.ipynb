{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220ba1c4-a628-4c81-afd8-50ae27f8ab56",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating a vectorstore with Amazon Bedrock multimodal-embeddings\n",
    "\n",
    "This notebook gives a step-by-step tutorial to populate a vector database in [Opensearch Serverless](https://aws.amazon.com/opensearch-service/features/serverless/). These vector embeddings will be used by the Bedrock Agent to search for similar images in the provided vectorstore.\n",
    "\n",
    "This notebook is required if you would like to the agent to be able to take the `/image_look_up` action, otherwise you can directly run the `Create_Fashion_Agent.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193be29c-1a8c-422e-b3e6-ae1f9abccd53",
   "metadata": {},
   "source": [
    "#### Download the dataset locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02d7c71-383c-431e-a2eb-bc83f0480297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'clothing-dataset'...\n",
      "remote: Enumerating objects: 5792, done.\u001b[K\n",
      "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 5792 (delta 13), reused 3 (delta 1), pack-reused 5766\u001b[K\n",
      "Receiving objects: 100% (5792/5792), 152.92 MiB | 29.20 MiB/s, done.\n",
      "Resolving deltas: 100% (14/14), done.\n",
      "Updating files: 100% (5759/5759), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/alexeygrigorev/clothing-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60b8a5-0c89-48d0-a452-9653f315b250",
   "metadata": {},
   "source": [
    "### Add all the dependencies/imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7944bd29-ddae-4b12-965d-9e7499b7ae5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexhrn/miniconda3/envs/temp-agents/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from opensearchpy import AWSV4SignerAuth, OpenSearch, RequestsHttpConnection\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a65168",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    os.path.join(Path(os.path.abspath(\"\")), \"config.yml\"), \"r\"\n",
    ") as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "105aad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"variables.json\", \"r\") as f:\n",
    "    variables = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "403b640c-c641-46d1-b9ce-a64f4337566f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_session = boto3.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "486b8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Define output vector size â€“ 1,024 (default), 384, 256\n",
    "\n",
    "EMBEDDING_CONFIG = {\n",
    "    \"embeddingConfig\": {\"outputEmbeddingLength\": int(config[\"embeddingSize\"])}\n",
    "}\n",
    "\n",
    "\n",
    "class OpensearchIngestion:\n",
    "    def __init__(self, client, session=None):\n",
    "        self.client = client\n",
    "        self.session = session if session else boto3.Session()\n",
    "        self.region = self.session.region_name\n",
    "\n",
    "    def put_bulk_in_opensearch(self, docs):\n",
    "        print(f\"Putting {len(docs)} documents in OpenSearch\")\n",
    "        success, failed = self.client.bulk(docs)\n",
    "        return success, failed\n",
    "\n",
    "    def check_index_exists(self, index_name):\n",
    "        return self.client.indices.exists(index=index_name)\n",
    "\n",
    "    def create_index(self, index_name):\n",
    "        if not self.check_index_exists(index_name):\n",
    "            settings = {\n",
    "                \"settings\": {\n",
    "                    \"index.knn\": True,\n",
    "                }\n",
    "            }\n",
    "            response = self.client.indices.create(index=index_name, body=settings)\n",
    "            return bool(response[\"acknowledged\"])\n",
    "        return False\n",
    "\n",
    "    def create_index_mapping(self, index_name):\n",
    "        response = self.client.indices.put_mapping(\n",
    "            index=index_name,\n",
    "            body={\n",
    "                \"properties\": {\n",
    "                    \"vector_field\": {\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": config[\"embeddingSize\"],\n",
    "                        \"method\": {\n",
    "                            \"name\": \"hnsw\",\n",
    "                            \"engine\": \"nmslib\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"image_b64\": {\"type\": \"text\"},\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "        return bool(response[\"acknowledged\"])\n",
    "\n",
    "    def get_bedrock_client(self):\n",
    "        return self.session.client(\"bedrock-runtime\", region_name=self.region)\n",
    "\n",
    "    def create_titan_multimodal_embeddings(\n",
    "        self,\n",
    "        image_path: str = \"None\",\n",
    "        text: str = \"None\",\n",
    "    ):\n",
    "        \"\"\"Creates the titan embeddings from the provided image and/or text.\"\"\"\n",
    "        payload_body = {}\n",
    "\n",
    "        if image_path and image_path != \"None\":\n",
    "            payload_body[\"inputImage\"] = self.get_encoded_image(image_path)\n",
    "        if text and (text != \"None\"):\n",
    "            payload_body[\"inputText\"] = text\n",
    "        if (image_path == \"None\") and (text == \"None\"):\n",
    "            raise \"please provide either an image and/or a text description\"\n",
    "\n",
    "        bedrock_client = self.get_bedrock_client()\n",
    "\n",
    "        response = bedrock_client.invoke_model(\n",
    "            body=json.dumps({**payload_body, **EMBEDDING_CONFIG}),\n",
    "            modelId=\"amazon.titan-embed-image-v1\",\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\",\n",
    "        )\n",
    "        vector = json.loads(response[\"body\"].read())\n",
    "        return (payload_body, vector)\n",
    "\n",
    "    def get_encoded_image(self, image_path: str):\n",
    "        max_height, max_width = 1024, 1024  # Conservative Limit. Can increase to 2048\n",
    "        # Open the image and compress it if greater than the defined max size.\n",
    "        with Image.open(image_path) as image:\n",
    "            if (image.size[0] * image.size[1]) > (max_height * max_width):\n",
    "                image.thumbnail((max_height, max_width))\n",
    "                resized_img = image.copy()\n",
    "            else:\n",
    "                resized_img = image\n",
    "            img_byte_array = io.BytesIO()\n",
    "            resized_img.save(img_byte_array, format=image.format)\n",
    "            img_bytes = img_byte_array.getvalue()\n",
    "\n",
    "        # Encode the image to base64\n",
    "        image_encoded = base64.b64encode(img_bytes).decode(\"utf8\")\n",
    "        return image_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b29ad34d-43ae-4230-9062-1a699134e11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a client for OSS\n",
    "client = boto3_session.client(\"opensearchserverless\")\n",
    "service = \"aoss\"\n",
    "region = boto3_session.region_name\n",
    "credentials = boto3_session.get_credentials()\n",
    "AWSAUTH = AWSV4SignerAuth(credentials, region, \"aoss\")\n",
    "for key in variables[\"FashionAgentStack\"].keys():\n",
    "    if key.startswith(\"OpenSearchServerlessConstructsFashionAgentStackOSSEndpoint\"):\n",
    "        host = variables[\"FashionAgentStack\"][key].removeprefix(\"https://\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0c3d4-885b-44ee-94af-e35c4761445e",
   "metadata": {},
   "source": [
    "#### Initialize an Opensearch client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcec490b-5724-4335-85e0-75e87e7fc84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the client with SSL/TLS enabled.\n",
    "OSSclient = OpenSearch(\n",
    "    hosts=[{\"host\":host , \"port\": 443}],\n",
    "    http_auth=AWSAUTH,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    pool_maxsize=20,\n",
    "    timeout=3000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b97446-cec3-4166-abd6-db40e75936a0",
   "metadata": {},
   "source": [
    "### Create an index for the Opensearch ingestion\n",
    "Opensearch Ingestion class (created in opensearch_utils.py) contains helper functions for the document processing and ingestion into the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fbf1e17-81cf-4734-b0b7-aedcc03169b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oss_instance = OpensearchIngestion(\n",
    "    client=OSSclient,\n",
    "    session=boto3_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77689c83-0c8e-4825-9103-1b121b273c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oss_instance.create_index(config[\"opensearch\"][\"opensearch_index_name\"])\n",
    "oss_instance.create_index_mapping(config[\"opensearch\"][\"opensearch_index_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd340ec2-b945-4a64-b949-7c034b57c33b",
   "metadata": {},
   "source": [
    "### Ingest the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaee504f-934f-40b8-9295-c72203dfadb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = \"clothing-dataset/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e97f1da8-c511-4ad6-b112-f8bb8c231524",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5756/5756 [1:32:09<00:00,  1.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion Complete. Failed ingestion for the following: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "failed = []\n",
    "for image_name in tqdm(os.listdir(dataset_path)):\n",
    "    image = dataset_path + image_name\n",
    "    try:\n",
    "        (data, embedding) = oss_instance.create_titan_multimodal_embeddings(\n",
    "            image_path=image\n",
    "        )\n",
    "        img_id = image.rsplit(\"/\", 1)[1].split(\".\")[0]\n",
    "        # print(img_id)\n",
    "        body = {\n",
    "            \"vector_field\": embedding[\"embedding\"],\n",
    "            \"image_b64\": data[\"inputImage\"],\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Exception thrown in image {image}: {e}\")\n",
    "        continue\n",
    "    # Ingest the images one by one.\n",
    "    status = oss_instance.client.index(\n",
    "        index=config[\"opensearch\"][\"opensearch_index_name\"],\n",
    "        body=body,\n",
    "    )\n",
    "    if status[\"result\"] != \"created\":\n",
    "        failed.append(image)\n",
    "\n",
    "print(f\"Ingestion Complete. Failed ingestion for the following: {failed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a48958",
   "metadata": {},
   "source": [
    "##### Clean up will be done together by destroying the CDK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
