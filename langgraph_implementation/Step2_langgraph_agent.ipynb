{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4691aa21-e28b-4ae2-8a5f-1e64993483e9",
   "metadata": {},
   "source": [
    "# Craft your style with AI: Building a Virtual Sylist Agent Using Amazon Bedrock and LangGraph\n",
    "\n",
    "\n",
    "## Lab 2 - Creating and testing our fashion agent\n",
    "\n",
    "\n",
    "In this lab, we will create create and test our Fashion Agent\n",
    "\n",
    "![agent_architecture](../images/agent_architecture2.png)\n",
    "\n",
    "The agent that we are creating has the capability of performing the following tasks:\n",
    "- **Image-to-Image or Text-to-Image Search**: Allows users to search for products from the catalog that are similar to styles they like.\n",
    "- **Text-to-Image Generation**: If the desired style is not available in the database, it can generate customized images based on the user's query.\n",
    "- **Weather API Integration**: By fetching weather information from the location mentioned in the user's prompt, the agent can suggest appropriate outfits for the occasion.\n",
    "- **Outpainting**: Users can upload an image and request to change the background, allowing them to visualize their preferred styles in different settings.\n",
    "- **Inpainting**: Enables users to modify specific clothing items in an uploaded image, such as changing the design or color.\n",
    "- **Handle human input**: the agent can require human input from the agent's actions or thoughts\n",
    "\n",
    "### Environment setup \n",
    "This has been tested in `conda_python3` Jupyter Notebook kernel with `ml.t3.medium`\n",
    "\n",
    "### Install the requirements\n",
    "Before getting started, let's install some pre-requisite packages so that we can work LangChain and LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed16cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet langgraph \"langchain>=0.2.13,<0.3.0\" langchain-aws opensearch-py\n",
    "!pip install --upgrade pydantic --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f3ed8-1d6a-491c-be5b-7e7ca225d5d6",
   "metadata": {},
   "source": [
    "### Load parameters for S3 setup\n",
    "Next we will load some parameters from AOSS. Since we have already created the collection for you, you can access the required parameters using [AWS Systems Manager Parameter Store](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ae867-8c75-47fa-9e83-666aa5020d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from random import randint\n",
    "\n",
    "ssm_client = boto3.client('ssm')\n",
    "\n",
    "response = ssm_client.get_parameters(\n",
    "    Names=[\n",
    "        'AOSSCollectionName', 'AOSSEmbeddingSize', 'AOSSHost', 'AOSSIndexName', 'S3BucketName'\n",
    "    ]\n",
    ")\n",
    "param_dict = {}\n",
    "for parameter in response['Parameters']:\n",
    "    param_dict[parameter['Name']] = parameter['Value']\n",
    "\n",
    "os.environ[\"region\"] = param_dict['AOSSHost'].split(\".\")[1]\n",
    "os.environ[\"index_name\"] = param_dict['AOSSIndexName']\n",
    "os.environ[\"collection_name\"] = param_dict['AOSSCollectionName']\n",
    "os.environ[\"aoss_host\"] = param_dict['AOSSHost']\n",
    "os.environ[\"s3_bucket\"] = param_dict['S3BucketName']\n",
    "os.environ[\"embeddingSize\"] = param_dict['AOSSEmbeddingSize']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5467297-5639-4907-b7ae-e342b49254c7",
   "metadata": {},
   "source": [
    "### Importing libraries and setting up boto3 client and other dependencies\n",
    "Let's import the packages for langchain and other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662a65c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from random import randint\n",
    "from helpers import download_from_s3\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, AIMessage\n",
    "\n",
    "from graph import graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5422b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RECURSION_LIMIT = 10\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "\n",
    "def get_langgraph_config():\n",
    "    thread_id = randint(0, 9999)\n",
    "    langgraph_config = {\n",
    "        \"recursion_limit\": RECURSION_LIMIT,\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id\n",
    "        }\n",
    "    }\n",
    "    return langgraph_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb3381-7b76-4382-9452-4a272ba06a44",
   "metadata": {},
   "source": [
    "### Looking at our agent graph\n",
    "We already created the structured of our agent using the `graph.py` python file. Go ahead and check the file to learn how to create an agent using LangGraph.\n",
    "\n",
    "Let's now take a look a the agent graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95553acd-b9c3-4e2d-9daa-22a33c4176c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ddf6a8-f52e-4053-8680-5ae345bdb697",
   "metadata": {},
   "source": [
    "### Create support function to handle user prompts\n",
    "\n",
    "We will now create a support ticket to handle the user messages and handle image inputs.\n",
    "We will also use this function to set our agent instruction using system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b89373-77fc-48ef-b3e3-1cf95f4fe110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompts(user_input, image=None, messages=None):\n",
    "    system_prompt = \"\"\"\n",
    "        You are a smart and quirky AI Stylist.\n",
    "        You answer questions about clothes to wear. \n",
    "        You have to understand the user question and give precise answer to the user.\n",
    "        <Instructions> \n",
    "            1/ Try to take weather and occasion into your suggestions.\n",
    "            2/ If you do not find any relevant image in the database, generate an image using your tools. \n",
    "            3/ Try to respond the user with a relevant image.\n",
    "    \"\"\"\n",
    "    \n",
    "    if image:\n",
    "        if 's3://' not in image:\n",
    "            # copy image into s3\n",
    "            s3_client.upload_file(image, os.environ[\"s3_bucket\"], image)\n",
    "            user_input += f'The photo is avalailable at s3://{os.environ[\"s3_bucket\"]}/{image}'\n",
    "        else:\n",
    "            user_input += f'The photo is avalailable at {image}'\n",
    "    if messages is None:\n",
    "        messages = [HumanMessage(content=user_input)]\n",
    "    else:\n",
    "        messages.append(HumanMessage(content=user_input))\n",
    "    prompt = [SystemMessage(content=system_prompt)] + messages \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8e93f",
   "metadata": {},
   "source": [
    "### Define User Question\n",
    "\n",
    "Let's now test our agent with a user query and a photo. To do so, let's explore the inpainting functionality and make our top green.\n",
    "\n",
    "For doing so let's use this reference image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e95e0-4378-4cb6-b17a-8deeb8d3d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "display(Image(filename=\"Fashion-Dataset-Images-Western-Dress/WesternDress_Images/1001.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a47a3-d601-4681-a167-7bb07347a400",
   "metadata": {},
   "source": [
    "We can use the prompt `Can you change the color of the top to green?` to change the top from this photo to green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d6ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_QUERY = \"Can you change the color of the top to green? \"\n",
    "photo = \"Fashion-Dataset-Images-Western-Dress/WesternDress_Images/1001.jpg\"\n",
    "input_message = create_prompts(USER_QUERY, image=photo)\n",
    "input_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236c2deb-defa-4f54-b54b-81f180ced87e",
   "metadata": {},
   "source": [
    "### Invoking the agent with the messages\n",
    "Now that we have created the system prompt and user input required to invoke the agent, let's do so using LangGraph [stream](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream) functionality.\n",
    "\n",
    "To do so, we will create the support function `invoke_agent` that help us invoking the LangGraph agent with the user input messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56df0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_agent(input_message):\n",
    "    s3_path = \"\"\n",
    "    for out in graph.stream(\n",
    "        {\"messages\": input_message},\n",
    "        config=get_langgraph_config(),\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        msg = next(iter(out.values()))\n",
    "        last_msg = msg[-1]\n",
    "        if isinstance(last_msg, ToolMessage):\n",
    "            if last_msg.content.startswith(\"s3\"):\n",
    "                s3_path = last_msg.content\n",
    "                print(f\"\\nToolMessage: S3 Path for output image: {last_msg.content}\")\n",
    "            else:\n",
    "                print(f\"\\nToolMessage: {last_msg.content}\")\n",
    "        elif isinstance(last_msg, AIMessage):\n",
    "            if isinstance(last_msg.content,list) and last_msg.content[0][\"type\"]==\"tool_use\":\n",
    "                print(f\"\\nCalling a tool.. {last_msg.content[0]['name']} with input {last_msg.content[0]['input']}\")\n",
    "            print(\"\\nAIMessage:\")\n",
    "            print(last_msg.content)\n",
    "    s3_key = s3_path.replace(\"s3://\"+os.environ[\"s3_bucket\"]+\"/\", '')\n",
    "    return s3_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d64812-2768-4107-8d92-5dc1dc5c9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = invoke_agent(input_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6951ef9-d999-41d3-9075-ff1ae00ab3bb",
   "metadata": {},
   "source": [
    "### Visualizing results\n",
    "Our agent creates images and store them to [Amazon S3](https://aws.amazon.com/s3/). Let's check the result by downloading the image produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8b403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_from_s3(os.environ[\"s3_bucket\"], key=s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c13ec9-ab8d-4aa3-9267-ff18fc97195a",
   "metadata": {},
   "source": [
    "### Testing other tools\n",
    "\n",
    "Let's now test the agent with different prompts. We will use the following prompts:\n",
    "* Can you find me an image with dotted shirt and dark blue jeans?\n",
    "* Generate a pink dress with white dots\n",
    "* I'm going to attend a wedding at Los Angeles, can you generate a dress for me?\n",
    "\n",
    "To test the agent `image_lookup`, `get_image_gen` and `get_weather` tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980119a6-c69e-4438-a48f-b0067bc9e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_QUERY = \"Can you find me an image with dotted shirt and dark blue jeans? \"\n",
    "input_message = create_prompts(USER_QUERY)\n",
    "s3_key = invoke_agent(input_message)\n",
    "download_from_s3(os.environ[\"s3_bucket\"], key=s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c3ebe-0ac5-4ace-9a97-f71595664f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_QUERY = \"Generate a pink dress with white dots \"\n",
    "input_message = create_prompts(USER_QUERY)\n",
    "s3_key = invoke_agent(input_message)\n",
    "download_from_s3(os.environ[\"s3_bucket\"], key=s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab121da0-216e-44ec-8414-491ce7665217",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_QUERY = \"I'm going to attend a wedding at Los Angeles, can you generate a dress for me? \"\n",
    "input_message = create_prompts(USER_QUERY)\n",
    "s3_key = invoke_agent(input_message)\n",
    "download_from_s3(os.environ[\"s3_bucket\"], key=s3_key)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
